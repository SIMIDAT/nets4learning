The following describes how to create the `<NEW_ENTRY>.js` file, which defines the description of the dataset, the original dataset, the processing, the transformations to the dataset for processing, the models, controllers, as well as the possibility to overwrite the tutorial to provide additional contextual information about the dataset, the task and the objetives.

---

## 1. Define the class with dataset and model

This is a template of class with a data set, preprocessing, pre-trained models and Utilities for tabular classification model.

<details>
<summary class="n4l-summary-wiki">Code example</summary>

```tsx
export default class NEW_ENTRY extends I_MODEL_TABULAR_CLASSIFICATION {
  static KEY = '<NEW_DATASET.KEY>'
  static URL = ''

  TITLE: string = '<NEW_DATASET>' // i18n
  i18n_TITLE: string = '<NEW_DATASET.i18n_TITLE>' // i18n.
  URL: string = ''

  // region ATTR
  LIST_EXAMPLES_RESULTS = []
  LIST_EXAMPLES = []
  DATA_OBJECT = {}
  TABLE_HEADER = []
  CLASSES = []
  FORM = [
    // EXAMPLE WITH ONLY ONE COLUMN OF DATASET CAR
    {
      'type'        : 'label-encoder',
      'index_column': 0,
      'name'        : '<NEW_DATASET.COLUMN_NAME>',
      'options'     : [
        { 'value': '<NEW_DATASET.COLUMN_NAME.ATTR.VALUE>', 'text': '<NEW_DATASET.COLUMN_NAME.ATTR.TEXT>' },
      ],
    },
    // ...
  ]
  DATA_DEFAULT = {}
  DATA_OBJECT_KEYS = {}
  DATA = []
  // endregion

  // Description with translations, more information in [i18n.md](../../../i18n.md)
  DESCRIPTION () {
    const prefix = 'datasets-models.0-tabular-classification.<NEW_DATASET>.description.'
    return <>
      <h3><Trans i18nKey={this.i18n_TITLE} /></h3>
      <p><Trans i18nKey={prefix + 'text.0'} /></p>
      <p>
        <Trans i18nKey={prefix + 'text.1'}
               components={{
                 link1: <a href={this.URL} target={'_blank'} rel="noreferrer">link</a>,
               }} />
      </p>
      <details>
        <summary><Trans i18nKey={prefix + 'details-input.title'} /></summary>
        <ol>
          <li><Trans i18nKey={prefix + 'details-input.list.0'} /></li>
          // ...
        </ol>
      </details>
      // ...
    </>
  }

  async DATASETS () {
    const dataset_path: string = import.meta.env.VITE_PATH + '/datasets/tabular-classification/<NEW_DATASET>/'
    const dataframe_original: dfd.DataFrame = await dfd.readCSV(dataset_path + '<NEW_DATASET>.csv')
    const dataframe_processed: dfd.DataFrame = await dfd.readCSV(dataset_path + '<NEW_DATASET>.csv')
    const dataset_transforms = [
      // ...
      { column_transform: 'label-encoder', column_name: '<NEW_DATASET.COLUMN_NAME>' },
    ]
    const column_name_target = '<NEW_DATASET.COLUMN_NAME>'
    const encoders_map = DataFrameUtils.DataFrameEncoder(dataframe_original, dataset_transforms)
    dataframe_processed = DataFrameUtils.DataFrameTransform(dataframe_processed, dataset_transforms)

    const dataframe_X = dataframe_processed.drop({ columns: [column_name_target] })
    const dataframe_y = dataframe_processed[column_name_target]

    const scaler: dfd.MinMaxScaler = new dfd.MinMaxScaler()
    scaler.fit(dataframe_X)
    const X = scaler.transform(dataframe_X)

    const oneHotEncoder: dfd.OneHotEncoder = new dfd.OneHotEncoder()
    oneHotEncoder.fit(dataframe_y)
    const y = oneHotEncoder.transform(dataframe_y)

    return [
      {
        is_dataset_upload   : false,
        is_dataset_processed: true,
        path                : dataset_path,
        info                : '<NEW_DATASET>.names',
        csv                 : '<NEW_DATASET>.csv',
        dataframe_original  : dataframe_original,
        dataset_transforms  : dataset_transforms,
        dataframe_processed : dataframe_processed,
        data_processed      : {
          X                 : X,
          y                 : y,
          missing_values    : false,
          encoders          : encoders_map,
          scaler            : scaler,
          column_name_target: column_name_target,
          classes           : this.CLASSES,
          attributes        : this.FORM,
        }
      }
    ]
  }

  // https://stackoverflow.com/questions/59182682/what-is-the-difference-between-tensorflow-js-layers-model-and-graph-model
  async LOAD_GRAPH_MODEL (callbacks) {
    return await tfjs.loadGraphModel(import.meta.env.VITE_PATH + '/models/00-tabular-classification/<NEW_DATASET>/my-new-model.json', {
      onProgress: callbacks.onProgress,
    })
  }

  async LOAD_LAYERS_MODEL (callbacks) {
    return await tfjs.loadLayersModel(import.meta.env.VITE_PATH + '/models/00-tabular-classification/<NEW_DATASET>/my-new-model.json', {
      onProgress: callbacks.onProgress,
    })
  }

  PREDICT (model, input) {
    return model.predict(input)
  }

  JOYRIDE () {
    // ...
  }

}
```

</details>

---

### 2.1. Define the description

An example of a tabular classification model in nets4learning must have a description to provide context and understanding of the work, this is obtained by including information about the dataset, references, authors, information about papers, etc. With this we provide very useful information to the user, if the user decides to research about the work.

We also include information about the characteristics of the model, the input data it should receive and the type of output it should provide.

To make all this work, we need to include this translated information, you can find more information in the i18n section.

<details>
<summary class="n4l-summary-wiki">Code example</summary>


```jsx
DESCRIPTION () {
  const prefix = 'datasets-models.0-tabular-classification.<NEW_DATASET>.description.'
  return <>
    <p><Trans i18nKey={prefix + 'text-1'} /></p>
    <p>
      <Trans i18nKey={prefix + 'text-2'}
             components={{
               link1: <a href={this.URL}
                         target="_blank"
                         rel="noreferrer">link</a>,
             }}
      />
    </p>
    <details>
      <summary><Trans i18nKey={prefix + 'details-input.title'} /></summary>
      <ol>
        <li><Trans i18nKey={prefix + 'details-input.list.0'} /></li>
        // ...
      </ol>
    </details>
    <details>
      <summary><Trans i18nKey={prefix + 'details-output.title'} /></summary>
      <ol>
        <li><Trans i18nKey={prefix + 'details-output.list.0'} /></li>
        // ...
      </ol>
    </details>
    <details>
      <summary><Trans i18nKey={prefix + 'details-references.title'} /></summary>
      <ol>
        <li><Trans i18nKey={prefix + 'details-references.list.0'} /></li>
        // ...
      </ol>
    </details>
    <details>
      <summary>BibTex</summary>
      <pre>@BibTex ...</pre>
    </details>
  </>
}
```

</details>

---

### 2.2. Preprocessing of dataset

The objective of data preprocessing is to improve the quality of the data and make them more suitable for training.

In pre-processing we must transform the data so that only the necessary data is provided and in the appropriate format so that our model does not contain noise.

We must analyze the data types of each feature of the dataset (numeric, floating, binary, tabular, etc.) to perform the appropriate transformations to the dataset.


<details>
<summary class="n4l-summary-wiki">Code example</summary>

This code correspond with the model of Car evaluation, in this code you can look at an example that who works the preprocessing.

```js
const dataset_path = import.meta.env.VITE_PATH + '/models/00-tabular-classification/car/'
const dataframe_original = await dfd.readCSV(dataset_path + 'car.csv')
let dataframe_processed = await dfd.readCSV(dataset_path + 'car.csv')
// @formatter:off
const dataset_transforms = [
  {  column_transform: 'label-encoder', column_name: 'Buying' },
  {  column_transform: 'label-encoder', column_name: 'Maint' },
  {  column_transform: 'label-encoder', column_name: 'Doors' },
  {  column_transform: 'label-encoder', column_name: 'Persons' },
  {  column_transform: 'label-encoder', column_name: 'Lug_boot' },
  {  column_transform: 'label-encoder', column_name: 'Safety' },
  {  column_transform: 'label-encoder', column_name: 'Result' },
]
// @formatter:on
const column_name_target = 'Result'
const encoders_map = DataFrameUtils.DataFrameEncoder(dataframe_original, dataset_transforms)
dataframe_processed = DataFrameUtils.DataFrameTransform(dataframe_processed, dataset_transforms)

const dataframe_X = dataframe_processed.drop({ columns: [column_name_target] })
const dataframe_y = dataframe_processed[column_name_target]

const scaler = new dfd.MinMaxScaler()
scaler.fit(dataframe_X)
const X = scaler.transform(dataframe_X)

const oneHotEncoder = new dfd.OneHotEncoder()
oneHotEncoder.fit(dataframe_y)
const y = oneHotEncoder.transform(dataframe_y)

const label_encoder_y = new dfd.LabelEncoder()
label_encoder_y.fit(dataframe_y.values)
const classes = Object.keys(label_encoder_y.$labels)
```

</details>

---

### 2.3. Load the model

As you remember, Nets4Learning has two modes in tabular classification, pre-trained models and training models. For this part we are going to define the model for when we work on trained models.

Tensorflow provides two methods of loading models, nets4Learning we mainly use `tf.loadLayersModel(pathOrIOHandler, options?)` as it loads the topology and weights of the pre-trained models.

You can use `tf.loadGraphModel(pathOrIOHandler, options?)` to have users create their own topologies and define the weights.

<details>
<summary class="n4l-summary-wiki">Code example</summary>

```js
async LOAD_GRAPH_MODEL (callbacks) {
  return await tf.loadGraphModel(import.meta.env.VITE_PATH + '/models/00-tabular-classification/<NEW_DATASET>/my-model-<NEW_DATASET>.json', {
    onProgress: callbacks.onProgress,
  })
}

async LOAD_LAYERS_MODEL (callbacks) {
  return tf.loadLayersModel(import.meta.env.VITE_PATH + '/models/00-tabular-classification/<NEW_DATASET>/my-model-<NEW_DATASET>.json', {
    onProgress: callbacks.onProgress,
  })
}
```

</details>

---

## 3. Bind the class with the application

Add the class in file [index.js](https://github.com/SIMIDAT/nets4learning/tree/main/src/pages/playground/0_TabularClassification/models/index.js) of this task and [DATA_MODEL.js](https://github.com/SIMIDAT/nets4learning/blob/main/src/DATA_MODEL.js)

A complete example of model class can be found at this link [MODEL_CAR.js](https://github.com/SIMIDAT/nets4learning/blob/main/src/pages/playground/0_TabularClassification/models/MODEL_CAR.js).

<details>
<summary class="n4l-summary-wiki">Code example</summary>

### /src/pages/playground/0_TabularClassification/models/index.js

```js
import I_MODEL_TABULAR_CLASSIFICATION from './_model'
import NEW_ENTRY from './NEW_ENTRY'

const MAP_TC_CLASSES = {
  // ...
  [NEW_ENTRY.KEY]: MODEL_NEW_DATASET,
}

export {
  I_MODEL_TABULAR_CLASSIFICATION,
  NEW_ENTRY, 
  
  MAP_TC_CLASSES,
}
```

### /src/DATA_MODEL.js

```js

const TASK_MODEL_OPTIONS_CLASS = {
  [TASKS.TABULAR_CLASSIFICATION]: {
    // ...
    [<NEW_ENTRY>.KEY]: { _class_: <NEW_ENTRY> },
  }
}

const TASK_DATASET_OPTIONS = {
  [TASKS.TABULAR_CLASSIFICATION]: [
    // ...
    { i18n: 'datasets-models.0-tabular-classification.list-datasets.0-option-<NEW_ENTRY>', value: <NEW_ENTRY>.KEY },
  ]
  // ...
}

```

</details>